<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Draw a ROC curve, estimate good cut-offs and compute validity measures
for each cut-off</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="../../R.css">
</head><body>

<table width="100%" summary="page for ROC {unknown}"><tr><td>ROC {unknown}</td><td align="right">R Documentation</td></tr></table>
<h2>Draw a ROC curve, estimate good cut-offs and compute validity measures
for each cut-off</h2>


<h3>Description</h3>

<p>
Draw a non-parametric (empirical) ROC curve and compute test sensitivity,
specificity, predictive values and likelihood ratios (and respective confidence
limits) for each decision threshold. Estimate good decision threshold by a
variety of methods.
</p>


<h3>Usage</h3>

<pre>
ROC(gold,
    test,
    CL = 0.95,
    Cost = 1,
    Prevalence = 0,
    Plot = TRUE,
    Plot.point = "Min.ROC.Dist",
    Print.full = FALSE,
    Print = TRUE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>gold</code></td>
<td>
The reference standard. A column in a dataframe indicating the classification
by the reference test. The reference standard must have two levels: must be
coded either as 0 - without target disease - or 1 - with the target disease;
or could be coded <a href="../../base/html/as.factor.html">as.factor</a> with the words "negative" - without target disease - and
"positive"  - with the target disease.</td></tr>
<tr valign="top"><td><code>test</code></td>
<td>
The index test or test under evaluation. A column in a dataframe or
indicating the test results in a continuous scale. May also work with discrete
ordinal scale.</td></tr>
<tr valign="top"><td><code>CL</code></td>
<td>
Confidence limit. The limits of the confidence interval. Must be coded
as number in a range from 0 to 1. Default value is 0.95</td></tr>
<tr valign="top"><td><code>Cost</code></td>
<td>
Cost = cost(FN)/cost(FP). MCT will be used to estimate a
good cut-off. It is a value in a range from 0 to infinite.
Could be financial cost or a health outcome with the perception that FN are
more undesirable than FP (or the other way around). This item will run
into MCT (misclassification cost term) - (1-prevalence)*(1-Sp)+Cost*prevalence(1-Se).
Cost=1 means FN and FP have even cost. Cost = 0.9 means FP are 10 percent
more costly. Cost = 0.769 means that FP are 30 percent more costly. Cost =
0.555 means that FP are 80 percent more costly. Cost = 0.3 means that FP
are 3 times more costly. Cost = 0.2 means that FP are 5 times more costly.
</td></tr>
<tr valign="top"><td><code>Prevalence</code></td>
<td>
Prevalence of the disease in the population who the test will
be performed. If left 0 (the default value), this will be replaced by the
disease prevalence in the sample. This values will be used in the MCT and
Efficiency formulas to estime good cut-offs.</td></tr>
<tr valign="top"><td><code>Plot</code></td>
<td>
If FALSE, the ROC curve plot will not be displayed. Default is TRUE.</td></tr>
<tr valign="top"><td><code>Plot.point</code></td>
<td>
The method of best cut-off estimation which will be displayed
at ROC curve as a dot. Default is "Min.ROC.Dist". Possible options are:
<dt>"Max.Accuracy"</dt><dd>- the cut-off which maximize the accuracy;</dd>
<dt>"Max.DOR"</dt><dd>- the cut-off which maximize the diagnostic odds ratio;</dd>
<dt>"Error.rate"</dt><dd>- the cut-off which minimizes the error rate;</dd>
<dt>"Max.Accuracy.area"</dt><dd>- the cut-off which maximize the accuracy area;</dd>
<dt>"Max.Sens+Spec"</dt><dd>- the cut-off which maximize the sum of sensitivity
with specificity;</dd>
<dt>"Max.Youden"</dt><dd>- the cut-off which maximize the Youden index;</dd>
<dt>"Se=Sp"</dt><dd>- the cut-off which Sensitivity is equal to Specificity;</dd>
<dt>"Min.ROC.Dist"</dt><dd>- the cut-off which minimize the distance between
the curve and the upper left corner of the graph;</dd>
<dt>"Max.Efficiency"</dt><dd>- the cut-off which maximize the efficiency;</dd>
<dt>"Min.MCT"</dt><dd>- the cut-off which minimize the misclassification cost term.</dd>
</td></tr>
<tr valign="top"><td><code>Print.full</code></td>
<td>
If TRUE, a table with sensitivity, specificity, predictive values
and likelihood ratios (and respective confidence limits) for each decision
threshold will be displayed.</td></tr>
<tr valign="top"><td><code>Print</code></td>
<td>
If FALSE, no results (detailed below in vlaues section) will be displayed on the
output window. Default is TRUE</td></tr>
</table>

<h3>Details</h3>

<p>
Tests results matching the cut-off values will be considered a positive test.
ROC assumes that subjects with higher values of the test are with the target
condition and those with lower values are without the target condition. Tests
the have a behavior like glucose (middle values are supposed to be normal and
extreme values are supposed to be abnormal) and immunefluorescence (lower
values - higher dilutions - are suppose to be abnormal) will not be correctly
analyzed. In the latter example, multiplying the test results by -1 or other
transformation before analysis could make it work. The result table with the
Print.full option, has more columns than can be shown in the screen. R
automatically  shows these columns below, therefore one has to be careful when
relating the corresponding lines.
<dt>1</dt><dd>Diagnostic odds ratio: </dd>
<i>DOR = (TP*TN)/(FN*FP); the same as: DOR = PLR/NLR</i>
<dt>2</dt><dd>Accuracy area: </dd>
<i>AA = (TP*TN)/((TP+FN)*(FP+TN))</i>
<dt>3</dt><dd>Youden index: </dd>
<i>Y = Se+Sp-1; the same as: Y = Se-FPR</i>
<dt>4</dt><dd>Minimum ROC distance: </dd>
<i>m ROC Dis = (Sp-1)^2+(1-Se)^2</i>
<dt>5</dt><dd>Efficiency: </dd>
<i>Ef = Se*prevalence+(1-prevalence)*Sp</i>
<dt>6</dt><dd>Misclassification Cost Term: </dd>
<i>MCT = (1-prevalence)*(1-Sp)+(cost(FN)/cost(FP))*prevalence*(1-Se)</i>
</p>


<h3>Value</h3>

<table summary="R argblock">
<tr valign="top"><td><code>pop.prevalence</code></td>
<td>
The disease prevalence informed by the user. If not
informed, it will be the same as the sample prevalence.</td></tr>
<tr valign="top"><td><code>sample.prevalence</code></td>
<td>
The disease prevalence in the sample</td></tr>
<tr valign="top"><td><code>sample.size</code></td>
<td>
The number of subjects analyzed</td></tr>
<tr valign="top"><td><code>test.summary</code></td>
<td>
A table showing the quintiles, mean and standard deviation
of overall test results, test results from those with the target condition
and without the target condition</td></tr>
<tr valign="top"><td><code>AUC.summary</code></td>
<td>
A table showing the AUC estimated by DeLong method (trapezoidal)
and its confidence limits.</td></tr>
<tr valign="top"><td><code>test.best.cutoff</code></td>
<td>
A table showing the best cut-offs estimated by methods
described above, its corresponding sensitivity, specificity and positive
likelihood ratio (and their confidence limits)</td></tr>
</table>

<h3>Note</h3>

<p>
Bug reports, malfunctioning, or suggestions for further improvements can
be sent, preferentially, through the epidemiologic R list.
</p>


<h3>Author(s)</h3>

<p>
Pedro Brasil - <a href="mailto:pedro.brasil@ipec.fiocruz.br">pedro.brasil@ipec.fiocruz.br</a>
</p>


<h3>References</h3>

<p>
<dt>1</dt><dd>Knotterus. The Evidence Based Clinical Diagnosis; BMJBooks, 2002.</dd>
<dt>2</dt><dd>Xiou-Hua Zhou, Nancy A Obuchowsky, Donna McClish. Statistical Mehods
in diagnostic Medicine; Wiley, 2002.</dd>
<dt>3</dt><dd>Simel D, Samsa G, Matchar D (1991). Likelihood ratios with confidence:
Sample size estimation for diagnostic test studies. Journal of Clinical
Epidemiology 44: 763 - 770</dd>
<dt>4</dt><dd>S.B. Cantor, C.C. Sun, G. Tortolero-Luna, R. Richards-Kortum, and
M. Follen. (1999) A comparison of C/B ratios from studies using receiver
operating characteristic curve analysis. Journal of Clinical Epidemiology,
52(9):885-892.</dd>
<dt>5</dt><dd>Greiner, M. (1996) Two-graph receiver operating characteristic (TG-ROC):
update version supports optimisation of cut-off values that minimise
overall misclassification costs. J.Immunol.Methods 191:93-94.</dd>
</p>


<h3>See Also</h3>

<p>
<code><a href="../../../doc/html/search/SearchObject.html?diagnosis">diagnosis</a></code>,<code><a href="../../../doc/html/search/SearchObject.html?interact.ROC">interact.ROC</a></code>,<a href="../../PresenceAbsence/html/optimal.thresholds.html">optimal.thresholds</a>,
<a href="../../epicalc/html/roc.from.table.html">roc.from.table</a>,<a href="../../ROCR/html/prediction.html">prediction</a>
</p>


<h3>Examples</h3>

<pre>
# loading a dataset
data(tutorial)
# attaching a dataset
attach(tutorial)
# The reference standard is not in the correct format
# Recoding the reference standard to "positive" &amp; "negative"
tutorial$Gold2&lt;-as.factor(ifelse(Gold=="pos","positive","negative"))
# attaching the data set with the modifications
attach(tutorial)
# A little discription of the data set to check if it is ok!
str(tutorial)
# Running ROC analysis wtih the satandard options
ROC(Gold2,Test_B)
</pre>



<hr><div align="center">[Package <a href="00Index.html">Index]</a></div>

</body></html>
